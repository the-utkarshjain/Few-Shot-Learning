{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "kKkD0ATEzuAg"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import random\n",
        "from collections import defaultdict\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "device = \"cuda\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class OmniglotDataset(Dataset):\n",
        "  def __init__(self, nsupport: int, nquery: int, Train: bool):\n",
        "    assert nsupport + nquery <= 20, \"nsupport + nquery cannot be more than 20\"\n",
        "\n",
        "    self.nsupport = nsupport\n",
        "    self.nquery = nquery\n",
        "\n",
        "    self.transform = transforms.Compose([ transforms.ToTensor(), transforms.Resize((28,28)) ])\n",
        "    self.images_dataset = torchvision.datasets.Omniglot(root=\"./data\", download = True, background = Train, transform = self.transform)\n",
        "    \n",
        "    if Train:\n",
        "      self.num_classes = 964 \n",
        "    else:\n",
        "      self.num_classes = 659\n",
        "      \n",
        "    self.label_to_idx = defaultdict(list)\n",
        "\n",
        "    for i, datapoint in enumerate(self.images_dataset):\n",
        "      label = datapoint[1]\n",
        "      self.label_to_idx[label].append(i)\n",
        "    \n",
        "  def __len__(self):\n",
        "    return self.num_classes\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    idxs = self.label_to_idx[idx]\n",
        "    random.shuffle(idxs)\n",
        "\n",
        "    support_set = [1-self.images_dataset[i][0] for i in idxs[:self.nsupport]]\n",
        "    query_set = [1-self.images_dataset[i][0] for i in idxs[self.nsupport: self.nsupport + self.nquery]]\n",
        "\n",
        "    combined_set = support_set + query_set\n",
        "    combined_set = torch.stack(combined_set)\n",
        "\n",
        "    return combined_set.to(device)"
      ],
      "metadata": {
        "id": "s-ibrSTKm91E"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvolutionBlock(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels = 64):\n",
        "    super().__init__()\n",
        "\n",
        "    self.convBlock = nn.Sequential(\n",
        "        nn.Conv2d(in_channels, out_channels, 3, padding = 1),\n",
        "        nn.BatchNorm2d(out_channels),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(2)\n",
        "    )\n",
        "  \n",
        "  def forward(self, input):\n",
        "    return self.convBlock(input)\n",
        "\n",
        "class FewShotLearning(nn.Module):\n",
        "  def __init__(self, in_channels = 1, out_channels = 64):\n",
        "    super().__init__()\n",
        "\n",
        "    self.convBlocks = nn.Sequential(\n",
        "        ConvolutionBlock(in_channels = in_channels),\n",
        "        ConvolutionBlock(in_channels = out_channels),\n",
        "        ConvolutionBlock(in_channels = out_channels),\n",
        "        ConvolutionBlock(in_channels = out_channels),\n",
        "        nn.Flatten(start_dim = 1, end_dim = -1)\n",
        "    )\n",
        "\n",
        "  def forward(self, input):\n",
        "    return self.convBlocks(input)"
      ],
      "metadata": {
        "id": "A9CEUzURTFmW"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def episode(model, images, nsupport, nquery):\n",
        "  \"\"\"\n",
        "  images shape: [nways, nsupport + query, 1, 28, 28]\n",
        "  \"\"\"\n",
        "\n",
        "  nways = images.shape[0]\n",
        "\n",
        "  # embedding the images\n",
        "  images = images.view(-1, *images.size()[2:])\n",
        "  images = model(images)\n",
        "  images = images.view(nways, -1, *images.size()[1:])\n",
        "\n",
        "  # extracting the support images and computing the prototype\n",
        "  support_images = images[:, :nsupport]\n",
        "  support_images = torch.mean(support_images, dim = 1)\n",
        "\n",
        "  # extracting the query images\n",
        "  query_images = images[:, nsupport:]\n",
        "  query_images = query_images.reshape(-1, 64)\n",
        "\n",
        "  # computing the distance between query images and prototype\n",
        "  distance = torch.cdist(query_images, support_images)\n",
        "\n",
        "  target = []\n",
        "  for i in range(nways):\n",
        "    for j in range(nquery):\n",
        "      target.append(i)\n",
        "  \n",
        "  prediction = F.log_softmax(-1*distance, dim = -1)\n",
        "  predicted_class = torch.argmax(prediction, dim = -1)\n",
        "  target = torch.tensor(target, device=device, dtype = torch.long)\n",
        "\n",
        "  loss = F.nll_loss(prediction, target)\n",
        "  accuracy = torch.eq(predicted_class, target).float().mean()\n",
        "\n",
        "  return loss, accuracy"
      ],
      "metadata": {
        "id": "JLAk1YXPChzM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(model, testing_dataloader, nsupport, nquery):\n",
        "  total_accuracy = 0\n",
        "\n",
        "  for datapoint in testing_dataloader:\n",
        "    _, accuracy = episode(model, datapoint, nsupport, nquery)\n",
        "    total_accuracy += accuracy\n",
        "  \n",
        "  return total_accuracy/len(testing_dataloader)\n",
        "\n",
        "def train(model, optimizer, scheduler, training_dataloader, testing_dataloader, nsupport, nquery, epochs = 50):\n",
        "  print(f\"There are going to be {len(training_dataloader)} episodes in one epoch of training.\")\n",
        "  print()\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "    loss_every_epoch = []\n",
        "    accuracy_every_epoch = []\n",
        "\n",
        "    for datapoint in training_dataloader:\n",
        "      loss, accuracy = episode(model, datapoint, nsupport, nquery)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "      scheduler.step()\n",
        "\n",
        "      loss_every_epoch.append(loss.item())\n",
        "      accuracy_every_epoch.append(accuracy.item())\n",
        "    \n",
        "    print(f\"Epoch: {epoch} \\nTrain Loss: {np.round(np.mean(loss_every_epoch), decimals = 6)} \\t Accuracy: {np.round(np.mean(accuracy_every_epoch)*100, decimals = 3)}\")\n",
        "\n",
        "    model.eval()\n",
        "    testing_accuracy = test(model, testing_dataloader, nsupport, nquery)\n",
        "    model.train()\n",
        "\n",
        "    print(f\"Test Accuracy: {np.round(testing_accuracy.item()*100, decimals = 3)}\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "AI2EnOIMuL1P"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nsupport = 1\n",
        "nquery = 5\n",
        "\n",
        "training_dataset = OmniglotDataset(nsupport=nsupport,nquery=nquery, Train = True)\n",
        "testing_dataset = OmniglotDataset(nsupport=nsupport,nquery=nquery, Train = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tHDmCng0ph7",
        "outputId": "f5116b4a-45d7-49f6-ad58-4e1897993a2c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_nways = 5\n",
        "testing_nways = 5\n",
        "\n",
        "training_dataloader = DataLoader(training_dataset, batch_size = training_nways, shuffle = True)\n",
        "testing_dataloader = DataLoader(testing_dataset, batch_size = testing_nways, shuffle = True)"
      ],
      "metadata": {
        "id": "he3ltz1f1Px_"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FewShotLearning().to(device)\n",
        "optimizer = torch.optim.Adam(params=model.parameters() ,lr=0.001) \n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, 2000, gamma=0.5, last_epoch=-1)\n",
        "train(model, optimizer, scheduler, training_dataloader, testing_dataloader, nsupport, nquery)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsqAZVqlwqIk",
        "outputId": "2cf0837d-5502-4666-e487-7c527dc0fdd6"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are going to be 193 episodes in one epoch of training.\n",
            "\n",
            "Epoch: 0 \n",
            "Train Loss: 0.466694 \t Accuracy: 84.943\n",
            "Test Accuracy: 88.053%\n",
            "\n",
            "Epoch: 1 \n",
            "Train Loss: 0.253091 \t Accuracy: 91.684\n",
            "Test Accuracy: 90.197%\n",
            "\n",
            "Epoch: 2 \n",
            "Train Loss: 0.188804 \t Accuracy: 94.093\n",
            "Test Accuracy: 90.076%\n",
            "\n",
            "Epoch: 3 \n",
            "Train Loss: 0.184587 \t Accuracy: 94.508\n",
            "Test Accuracy: 91.159%\n",
            "\n",
            "Epoch: 4 \n",
            "Train Loss: 0.157052 \t Accuracy: 95.368\n",
            "Test Accuracy: 94.454%\n",
            "\n",
            "Epoch: 5 \n",
            "Train Loss: 0.14489 \t Accuracy: 95.751\n",
            "Test Accuracy: 93.053%\n",
            "\n",
            "Epoch: 6 \n",
            "Train Loss: 0.12511 \t Accuracy: 96.389\n",
            "Test Accuracy: 93.75%\n",
            "\n",
            "Epoch: 7 \n",
            "Train Loss: 0.128075 \t Accuracy: 95.938\n",
            "Test Accuracy: 92.023%\n",
            "\n",
            "Epoch: 8 \n",
            "Train Loss: 0.11653 \t Accuracy: 96.285\n",
            "Test Accuracy: 93.212%\n",
            "\n",
            "Epoch: 9 \n",
            "Train Loss: 0.094023 \t Accuracy: 97.036\n",
            "Test Accuracy: 95.379%\n",
            "\n",
            "Epoch: 10 \n",
            "Train Loss: 0.083858 \t Accuracy: 97.368\n",
            "Test Accuracy: 94.758%\n",
            "\n",
            "Epoch: 11 \n",
            "Train Loss: 0.076848 \t Accuracy: 97.762\n",
            "Test Accuracy: 94.076%\n",
            "\n",
            "Epoch: 12 \n",
            "Train Loss: 0.069271 \t Accuracy: 97.731\n",
            "Test Accuracy: 95.303%\n",
            "\n",
            "Epoch: 13 \n",
            "Train Loss: 0.093446 \t Accuracy: 96.793\n",
            "Test Accuracy: 95.939%\n",
            "\n",
            "Epoch: 14 \n",
            "Train Loss: 0.06407 \t Accuracy: 98.13\n",
            "Test Accuracy: 94.515%\n",
            "\n",
            "Epoch: 15 \n",
            "Train Loss: 0.073283 \t Accuracy: 97.845\n",
            "Test Accuracy: 95.667%\n",
            "\n",
            "Epoch: 16 \n",
            "Train Loss: 0.066823 \t Accuracy: 97.99\n",
            "Test Accuracy: 94.091%\n",
            "\n",
            "Epoch: 17 \n",
            "Train Loss: 0.06213 \t Accuracy: 98.073\n",
            "Test Accuracy: 94.379%\n",
            "\n",
            "Epoch: 18 \n",
            "Train Loss: 0.059359 \t Accuracy: 98.197\n",
            "Test Accuracy: 96.114%\n",
            "\n",
            "Epoch: 19 \n",
            "Train Loss: 0.066407 \t Accuracy: 98.088\n",
            "Test Accuracy: 94.151%\n",
            "\n",
            "Epoch: 20 \n",
            "Train Loss: 0.06042 \t Accuracy: 97.845\n",
            "Test Accuracy: 95.879%\n",
            "\n",
            "Epoch: 21 \n",
            "Train Loss: 0.068324 \t Accuracy: 98.01\n",
            "Test Accuracy: 96.151%\n",
            "\n",
            "Epoch: 22 \n",
            "Train Loss: 0.053016 \t Accuracy: 98.259\n",
            "Test Accuracy: 96.061%\n",
            "\n",
            "Epoch: 23 \n",
            "Train Loss: 0.048734 \t Accuracy: 98.487\n",
            "Test Accuracy: 95.091%\n",
            "\n",
            "Epoch: 24 \n",
            "Train Loss: 0.063748 \t Accuracy: 98.047\n",
            "Test Accuracy: 95.909%\n",
            "\n",
            "Epoch: 25 \n",
            "Train Loss: 0.049504 \t Accuracy: 98.378\n",
            "Test Accuracy: 96.265%\n",
            "\n",
            "Epoch: 26 \n",
            "Train Loss: 0.042947 \t Accuracy: 98.777\n",
            "Test Accuracy: 95.788%\n",
            "\n",
            "Epoch: 27 \n",
            "Train Loss: 0.044039 \t Accuracy: 98.508\n",
            "Test Accuracy: 96.061%\n",
            "\n",
            "Epoch: 28 \n",
            "Train Loss: 0.057689 \t Accuracy: 98.321\n",
            "Test Accuracy: 95.485%\n",
            "\n",
            "Epoch: 29 \n",
            "Train Loss: 0.047997 \t Accuracy: 98.528\n",
            "Test Accuracy: 95.97%\n",
            "\n",
            "Epoch: 30 \n",
            "Train Loss: 0.044122 \t Accuracy: 98.632\n",
            "Test Accuracy: 96.394%\n",
            "\n",
            "Epoch: 31 \n",
            "Train Loss: 0.044421 \t Accuracy: 98.632\n",
            "Test Accuracy: 96.129%\n",
            "\n",
            "Epoch: 32 \n",
            "Train Loss: 0.038347 \t Accuracy: 98.86\n",
            "Test Accuracy: 96.356%\n",
            "\n",
            "Epoch: 33 \n",
            "Train Loss: 0.03716 \t Accuracy: 98.736\n",
            "Test Accuracy: 96.333%\n",
            "\n",
            "Epoch: 34 \n",
            "Train Loss: 0.036927 \t Accuracy: 98.902\n",
            "Test Accuracy: 96.515%\n",
            "\n",
            "Epoch: 35 \n",
            "Train Loss: 0.039973 \t Accuracy: 98.788\n",
            "Test Accuracy: 96.273%\n",
            "\n",
            "Epoch: 36 \n",
            "Train Loss: 0.049505 \t Accuracy: 98.259\n",
            "Test Accuracy: 96.227%\n",
            "\n",
            "Epoch: 37 \n",
            "Train Loss: 0.049173 \t Accuracy: 98.425\n",
            "Test Accuracy: 96.629%\n",
            "\n",
            "Epoch: 38 \n",
            "Train Loss: 0.024385 \t Accuracy: 99.44\n",
            "Test Accuracy: 96.182%\n",
            "\n",
            "Epoch: 39 \n",
            "Train Loss: 0.062688 \t Accuracy: 98.135\n",
            "Test Accuracy: 95.583%\n",
            "\n",
            "Epoch: 40 \n",
            "Train Loss: 0.03743 \t Accuracy: 98.943\n",
            "Test Accuracy: 96.394%\n",
            "\n",
            "Epoch: 41 \n",
            "Train Loss: 0.038885 \t Accuracy: 98.86\n",
            "Test Accuracy: 96.515%\n",
            "\n",
            "Epoch: 42 \n",
            "Train Loss: 0.038682 \t Accuracy: 98.922\n",
            "Test Accuracy: 96.909%\n",
            "\n",
            "Epoch: 43 \n",
            "Train Loss: 0.031973 \t Accuracy: 99.295\n",
            "Test Accuracy: 95.394%\n",
            "\n",
            "Epoch: 44 \n",
            "Train Loss: 0.032674 \t Accuracy: 99.109\n",
            "Test Accuracy: 96.992%\n",
            "\n",
            "Epoch: 45 \n",
            "Train Loss: 0.044291 \t Accuracy: 98.674\n",
            "Test Accuracy: 96.758%\n",
            "\n",
            "Epoch: 46 \n",
            "Train Loss: 0.034995 \t Accuracy: 98.881\n",
            "Test Accuracy: 96.409%\n",
            "\n",
            "Epoch: 47 \n",
            "Train Loss: 0.0406 \t Accuracy: 98.668\n",
            "Test Accuracy: 95.705%\n",
            "\n",
            "Epoch: 48 \n",
            "Train Loss: 0.030015 \t Accuracy: 99.233\n",
            "Test Accuracy: 96.333%\n",
            "\n",
            "Epoch: 49 \n",
            "Train Loss: 0.039061 \t Accuracy: 98.819\n",
            "Test Accuracy: 97.212%\n",
            "\n"
          ]
        }
      ]
    }
  ]
}